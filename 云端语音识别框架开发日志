讯飞离线命令词集成日志
日期:2015/11/23-2015/11/27

主要工作量:
    √1)将离线命令词识别语音包(aitalk)集成到ros下,构建speechrecog package,建立"recognizer""trigger"两个节点.其中在"recognizer"节点中集成了讯飞离线命令词识别API,提供"command_recognize"服务,用于实现对命令词进行识别的功能;"trigger"节点用于触发"command_recognize"服务.
    √2)将离线语音合成(aisound)集成到"trigger"节点中,针对触发"command_recognize"服务返回回的识别结果,[提取有效的信息点,如"打电话给丁伟"中的"丁伟",],形成特定的反馈文本(比如,"好的,正在拨号给"丁伟",请稍等"),将该反馈文本利用离线语音合成(aisound)包中的语音合成(tts)API合成.wav音频,并播放.
    √3)构建运动指令"motion.bnf"语法文件,实现诸如"机器人前进,前进十米,向左前方前进五米,倒退,向后转,停止,转弯"等运动指令词. 
    √4)构建包含多任务范畴的语法文件,其作用相当于同时调用多个独立的语法文件.保证了识别内容的全面.目前涵盖的任务内容包含:1.运动指示<motion>(如:"前进十米""向左转90度")\ 2.打电话<call>(如:"打电话给丁伟""请拨打孟孟的号码")\ 3.打招呼<whoareyou>(如:"你是谁""你叫什么名字")\ 4.天气<weather>(如:"今天的天气如何""明天会下雨吗""明天有雾霾吗")\ 5.唱歌<song>(如:"唱首小苹果""唱一首圣诞歌")\ 6.导航<navigation>(如:"去电梯口|去卧室|到前边工位那边")
    5)对于aitalk开发包,构建两个语法文件(call.bnf && motion.bnf),研究如何解决加载多个语法文件的问题.


存在的问题:
   √1)离线命令词识别语音包(aitalk)中识别的音频文件的格式为.pcm格式,而之前的录音代码录制的音频格式为.wav,二者不一致:要解决把wav音频格式文件转化成pcm格式文件的问题.
    2)无法加载多个语法文件(其中,一个语法文件对应一个特定的功能内容,比如打电话\运动指示\迎宾问候等;同时加载多个语法文件,是为了实现"全面.综合"的内容识别.
    3)识别结果返回的字符串为xml文件格式,如:
      <?xml version='1.0' encoding='utf-8' standalone='yes' ?><nlp>
         <version>1.1</version>
         <rawtext>打电话给丁伟</rawtext>
         <confidence>87</confidence>
         <engine>local</engine>
         <result>
	    <focus>dialpre|contact</focus>
	    <confidence>0|0</confidence>
	    <object>
		    <dialpre id="10001">打电话给</dialpre>
		    <contact id="65535">丁伟</contact>
            </object>
         </result>
      </nlp>
      需要对该字符串进行处理,以提取出其中的目标string"打电话给丁伟" \ "打电话给" \ "丁伟";
      目前的解决方案: 1. 采用xml解析方式
                     2. 字符串处理方式


后续待解决问题:
   (一)输入及识别:
	     1)录音时长不受限
	     2)补充尽可能全面的语法识别文件
   (二)输出(反馈)
         √ ☆   1)集成讯飞离线语音合成(aisound)包:
               其作用方式为:接收到"recognizer"节点发布的识别结果(如,"打电话为丁伟")后,将文本"好的,正在拨号给丁伟,请稍等..."使用tts API合成为音频,并且播放!
             2)如何可以的话,添加"语义处理"模块,以对识别结果进行"理解与答复",并且"答复"结果以语音形式反馈给用户.

