讯飞离线命令词集成日志
日期:2015/11/23-2015/11/27

主要工作量:
    √1)将离线命令词识别语音包(aitalk)集成到ros下,构建speechrecog package,建立"recognizer""trigger"两个节点.其中在"recognizer"节点中集成了讯飞离线命令词识别API,提供"command_recognize"服务,用于实现对命令词进行识别的功能;"trigger"节点用于触发"command_recognize"服务.
    √2)将离线语音合成(aisound)集成到"trigger"节点中,针对触发"command_recognize"服务返回回的识别结果,[提取有效的信息点,如"打电话给丁伟"中的"丁伟",],形成特定的反馈文本(比如,"好的,正在拨号给"丁伟",请稍等"),将该反馈文本利用离线语音合成(aisound)包中的语音合成(tts)API合成.wav音频,并播放.
    √3)构建运动指令"motion.bnf"语法文件,实现诸如"机器人前进,前进十米,向左前方前进五米,倒退,向后转,停止,转弯"等运动指令词. 
    √4)构建包含多任务范畴的语法文件,其作用相当于同时调用多个独立的语法文件.保证了识别内容的全面.目前涵盖的任务内容包含:1.运动指示<motion>(如:"前进十米""向左转90度")\ 2.打电话<call>(如:"打电话给丁伟""请拨打孟孟的号码")\ 3.打招呼<whoareyou>(如:"你是谁""你叫什么名字")\ 4.天气<weather>(如:"今天的天气如何""明天会下雨吗""明天有雾霾吗")\ 5.唱歌<song>(如:"唱首小苹果""唱一首圣诞歌")\ 6.导航<navigation>(如:"去电梯口|去卧室|到前边工位那边")
    5)对于aitalk开发包,构建两个语法文件(call.bnf && motion.bnf),研究如何解决加载多个语法文件的问题.


存在的问题:
   √1)离线命令词识别语音包(aitalk)中识别的音频文件的格式为.pcm格式,而之前的录音代码录制的音频格式为.wav,二者不一致:要解决把wav音频格式文件转化成pcm格式文件的问题.
    2)无法加载多个语法文件(其中,一个语法文件对应一个特定的功能内容,比如打电话\运动指示\迎宾问候等;同时加载多个语法文件,是为了实现"全面.综合"的内容识别.
    3)识别结果返回的字符串为xml文件格式,如:
      <?xml version='1.0' encoding='utf-8' standalone='yes' ?><nlp>
         <version>1.1</version>
         <rawtext>打电话给丁伟</rawtext>
         <confidence>87</confidence>
         <engine>local</engine>
         <result>
	    <focus>dialpre|contact</focus>
	    <confidence>0|0</confidence>
	    <object>
		    <dialpre id="10001">打电话给</dialpre>
		    <contact id="65535">丁伟</contact>
            </object>
         </result>
      </nlp>
      需要对该字符串进行处理,以提取出其中的目标string"打电话给丁伟" \ "打电话给" \ "丁伟";
      目前的解决方案: 1. 采用xml解析方式
                     2. 字符串处理方式


后续待解决问题:
   (一)输入及识别:
	     1)录音时长不受限
	     2)补充尽可能全面的语法识别文件
   (二)输出(反馈)
         √ ☆   1)集成讯飞离线语音合成(aisound)包:
               其作用方式为:接收到"recognizer"节点发布的识别结果(如,"打电话为丁伟")后,将文本"好的,正在拨号给丁伟,请稍等..."使用tts API合成为音频,并且播放!
             2)如何可以的话,添加"语义处理"模块,以对识别结果进行"理解与答复",并且"答复"结果以语音形式反馈给用
///////////////////////////////////////////////////////////////////////////////////////////////////////////////
ros语义反馈处理开发
日期:2015/12/7-2015/12/11

主要工作量:
    待解决的问题:
    1)对于(运动指令)\(打电话)\(你是谁)\(天气)\(唱歌)\(导航)六个识别范围,解决6个识别范围对应的智能回答问题.
      着手点:
            1.使用字符串处理方法提取有效字段,以对应解决相应智能回答问题.
            2.调研HanLP自然语言处理Java工具包;[已完成调研,有调研报告一份<Hanlp调研报告.docx>,该工具包主要作用可以对语句进行切分;自动识别中国人名.音译名;提取关键字;简繁拼音转换;依存句法分析]目前的离线语音识别包,其语法文件的构建实际上等价于语句切分的功能.结论:可以暂停对该工具包的调研.
            3.6个识别范围主要是针对对机器人的命令指示类(即让机器人完成某个指定动作)的内容范围,除了whoareyou\weather之外,其余均不需要进行智能问答.针对智能问答的问题,调研讯飞的"开放语义"下的"智能问答",经过随机测试,其只可以完成诸如
              ----问:"你最最好了".答:"我能做的好,是因为我都在不断地学习,希望你一直这么喜欢我哦"
              ----问:"讯飞做的不错!" 答:"他们都这么夸我呢!"
              ----问:"你好" 答:"哇你好直接噢."

              而更多的测试,诸如"今天天气怎样"\"今天工作累吗"\"你会唱歌吗"\"你都会做什么"\"交个朋友吧"\"新年快乐"等均没有相应的应答.
              且该服务为在线服务,与本项目需要离线实现有悖.
              结论:暂且不考虑集成讯飞的"开放语义".
    遇到的问题
    1\ printf("\n%s\n", rec_rslt);
      为什么输出为:
�	0a	rsion='1.0' encoding='utf-8' standalone='yes' ?><nlp>
  <version>1.1</version>
  <rawtext>倒退跑</rawtext>
  <confidence>3</confidence>
  <engine>local</engine>
  <result>
    <focus>direction|pattern</focus>
    <confidence>0|0</confidence>
    <object>
      <direction id="65535">倒退</direction>
      <pattern id="65535">跑</pattern>
    </object>
  </result>
</nlp>


      
